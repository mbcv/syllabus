L1:曼哈顿距离算法---

L2:欧式距离---

折叶损失（hinge loss）:max(0,-)

平方折叶损失（L2-SVM）:max(0,-)2

深度学习网络框架实际上是包含一系列层并且记录所有层之间联系的计算图

通过前馈得到损失，通过反馈得到梯度，通过对梯度的使用来完成权值更新

前馈->反馈->更新 ->前馈->反馈->更新

图片问题，层数更重要些；简单的数据，深度就没有多大作用

加法门单元把输出的梯度相等地分发给它所有的输入，这一行为与输入值在前向传播时的值无关。这是因为加法操作的局部梯度都是简单的+1，所以所有输入的梯度实际上就等于输出的梯度，因为乘以1.0保持不变。

取最大值门单元对梯度做路由。和加法门不同，取最大值门将梯度转给其中一个输入，这个输入是在前向传播中值最大的那个输入。这是因为在取最大值门中，最高值的局部梯度是1.0，其余的是0。

乘法门单元相对不容易解释。它的局部梯度就是输入值，但是是相互交换之后的，然后根据链式法则乘以输出值的梯度。