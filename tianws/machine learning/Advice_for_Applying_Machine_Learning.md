##  十 应用机器学习的建议

### 10.1 Deciding What to Try Next

当我们运用训练好了的模型来预测未知数据的时候发现有较大的误差，我们下一步可以做什么？

1. 获得更多的训练实例————通常是有效的，但代价太大，下面的方法也可能有效，可考虑先采用下面的几种方法。
2. 尝试减少特征的数量。
3. 尝试获得更多的特征。
4. 尝试增加多项式特征。
5. 尝试减少归一化程度λ。
6. 尝试增加归一化程度λ。

我们不应该随机选择上面的某种方法来改进我们的算法，而是运用一些机器学习诊断法来帮助我们知道上面哪些方法对我们的算法是有效的。

###  10.2 Evaluating a Hypothesis(评估一个假设)

为了检验算法是否过拟合，我们将数据分成训练集和测试集，通常用70%的数据作为训练集，用剩下30%的数据作为测试集。很重要的一点是训练集和测试集均要含有各种类型的数据，通常我们要对数据进行“洗牌”，然后再分成训练集和测试集。

通过训练集让我们的模型学习得出其参数后，对测试集运用该模型，我们有两种方式计算误差：

1. 对于线性回归模型，我们利用测试集数据计算代价函数J
2. 对于逻辑回归模型，我们除了可以利用测试数据集来计算代价函数外：

![](../picture/AML/06.jpg)

可以对每一个测试集实例，计算：

![](../picture/AML/07.jpg)

然后对计算结果求平均。

### 10.3 Model Selection and Train_Validation_Test Sets

假设我们要在10个不同次数的二项式模型之间进行选择，显然次数越高的多项式模型越能够适应我们的训练集，但是适应训练集并不代表这能推广至一般情况，我们应该选择一个更能适应一般情况的模型。我们选择交叉验证集来帮助我们选择模型。

即：使用60%的数据作为训练集，使用20%的数据作为交叉验证集，使用20%的数据作为测试集。

模型选择的方法为：

1. 使用训练集训练出10个模型
2. 用10个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）
3. 选取代价函数值最小的模型
4. 用步骤3中选出的模型对测试集计算得出推广误差。

### 10.4 Diagnosing Bias vs. Variance（诊断偏差和方差）

当你运行一个学习算法的时候，如果这个算法表现的不理想，那么多半是出现两种情况：要么是偏差比较大（欠拟合），要么是方差比较大（过拟合）。弄清楚一个算法是偏差有问题还是方差有问题，还是两个都有问题对于改进学习算法的效果非常重要。

高偏差和高方差的问题基本上来说是欠拟合和过拟合的问题。

我们通常会将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图标上来帮助分析：

![](../picture/AML/01.jpg)

![](../picture/AML/02.jpg)

对与训练集，当d较小时，模型拟合程度更低，误差较大；随着d的增长，你和程度提高，误差减小。

对于交叉验证集，当d较小时，模型拟合程度低，误差较大；但是随着d的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。

如果我们的交叉验证集误差较大，我们如何判断是方差还是偏差呢？根据上面的图表，我们知道：

![](../picture/AML/03.jpg)

训练集误差和交叉验证集误差近似时：偏差/欠拟合
交叉验证集误差远大于训练集误差时：方差/过拟合

### 10.5 Regularization and Bias_Variance(归一化和偏差/方差)

![](../picture/AML/08.jpg)

![](../picture/AML/09.jpg)

当λ较小时，训练集误差较小（过拟合）而交叉验证集误差较大。

随着λ的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加。

###  10.6 Learning Curves(学习曲线)

学习曲线是学习算法的一个很好的合理检验（sanity check）。学习曲线是将训练集误差和交叉验证集误差作为训练集实例数量的函数绘制的图表。

即，如果我们有100行数据，我们从1行数据开始，逐渐学习更多行的数据。思想是：当训练较少行数据的时候，训练的模型将能够非常完美地适应较少的训练数据，但是训练出来的模型却不能很好地适应交叉验证集数据或测试集数据。

如何利用学习曲线识别高偏差/欠拟合：作为例子，我们尝试用一条直线来适应下面的数据，可以看出，无论训练集有多么大，误差都不会有太大改观：

![](../picture/AML/10.jpg)

也就是说高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助。

如何识别高方差/过拟合：假设我们使用一个非常高次的多项式模型，并且归一化非常小，可以看出，当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果。

![](../picture/AML/11.jpg)

### 10.7 Deciding What to Do Next Revisited(决定下一步做什么)

回顾我们之前提出的改进的方法，分别在什么情况下使用呢？

1. 获得更多的训练实例--解决高方差
2. 尝试减少特征的数量--解决高方差
3. 尝试获得更多的特征--解决高偏差
4. 尝试增加多项式特征--解决高偏差
5. 尝试减少归一化程度λ--解决高偏差
6. 尝试增加归一化程度λ--解决高方差

神经网络的方差和偏差：

![](../picture/AML/13.jpg)

使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小。

使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价较大，但是可以通过归一化手段来调整而更加适应数据。

通常选择较大的神经网络并采用归一化处理会比采用较小的神经网络效果更好。

对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地做选择，可以把数据分为训练集，交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络，然后选择交叉验证集代价最小的神经网络。

## 十一 机器学习系统的设计（Mechine Learning System Design）

### 11.1. Prioritizing What to Work On（首先要做什么）

以一个垃圾邮件分类器算法为例。

为了解决这样一个问题，我们首先要做的决定是如何选择并表达特征向量x。我们可以选择一个由100个最常出现在垃圾邮件中的词所构成的列表，根据这些词是否有在邮件中出现，来获得我们的特征向量（出现为1，不出现为0），尺寸为100*1。

为了构建这个分类器算法，我们可以做很多事，例如：

1. 收集更多的数据，让我们有更多的垃圾邮件和非垃圾邮件的样本。
2. 基于邮件的路由信息开发一系列复杂的特征。
3. 基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理。
4. 为探测刻意的拼写错误开发复杂的算法。

当我们使用机器学习的时候，总是可以“头脑风暴一下”，想出一堆方法，然后用更加系统性的方法，从一堆不同的方法中，选取合适的那个。

### 11.2 Error Analysis(误差分析)

构建一个学习算法的推荐方法为：

1. 从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法。
2. 绘制学习曲线，决定是增加更多的数据，或者添加更多的特征，还是其他选择。
3. 进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的实例，看看这些实例是否有某种系统化的趋势。

误差分析并不总能帮助我们判断应该采取怎样的行动，有时我们需要尝试不同的模型，然后进行比较，在模型比较时，用数值来判断哪一个模型更好更有效，通常我们是看交叉验证集的误差。

###  11.3 Error Metrics for Skewed Classes(类偏斜的误差度量)

类偏斜情况表现为我们的训练集中有非常多的同一种类的实例，只有很少或没有其他类的实例。

查准率（precision）和查全率（recall）

![](../picture/AML/15.jpg)

precision=预测为正的案例中实际为正的百分比

recall=实际为正的案例中成功预测的百分比

### 11.4 Trading Off Precision and Recall（查全率和查准率之间的权衡）

![](../picture/AML/16.jpg)

### 11.5 Data for Machine Learning(机器学习的数据)

“取得成功的人不是拥有最好算法的人，而是拥有最多数据的人”的前提假设：

特征值有足够的信息量，且我们有一类很好的函数。

关键的测试：

首先，一个人类学家看到了特征值x，能很有信息的预测出y值吗？因为这可以证明y可以根据特征值x被准确地预测出来。

其次，我们实际上能得到一组庞大的训练集，并且在这个训练集中训练一个有很多参数的学习算法吗？
