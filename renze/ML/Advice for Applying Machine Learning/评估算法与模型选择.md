####Debugging a learning algorithm###
当使用假设函数测试一组新的样本时产生了巨大的误差，这时应该怎么做？

 - 获取更多的训练样本（有时，更多的样本也于事无补）
 - 尝试更少的特征集
 - 或许需要用更多的特征
 - 尝试增加多项式特征
 - 增大或减小lambda
 
 >机器学习诊断法：是一种测试法，通过执行这种测试，能够深入了解某种算法是否有用，通常也能够告诉你，如果想要改进一种算法的效果，需要什么样的尝试。
 
评估一个假设函数：
将训练集分为两部分，前70%用作新的训练集，后30%用作测试集。（如果训练集是有序的或者是有规律的，则随机选取70%做训练集）

最小化训练误差 J(θ)

>**线性回归**：
![线性回归](http://pic-10062852.cos.myqcloud.com/mintheta.jpg)

>**逻辑回归**：
除了利用测试数据集来计算代价函数外
![逻辑回归](http://pic-10062852.cos.myqcloud.com/logisticMintheta.png)
还可以计算误分类的比率，对于每一个测试集实例，计算：
![误分类比率](http://pic-10062852.cos.myqcloud.com/%E8%AF%AF%E5%88%86%E7%B1%BB%E6%AF%94%E7%8E%87.png)
然后对计算结果求平均。


**交叉验证**
假设要在10个不同次数的二项式模型之间进行选择:
![10model](http://pic-10062852.cos.myqcloud.com/10model.png)

把训练集分为3部分，第一部分为训练集，第二部分为交叉验证集，第三部分为测试集。(60%  20%  20%)
![error](http://pic-10062852.cos.myqcloud.com/train-vali-testerror.png)

模型选择的方法：

 - 使用训练集训练出10个模型
 - 用10个模型分别对交叉验证集计算得到交叉验证误差（即代价函数的值）
 - 选取代价函数最小的模型
 - 用选出的模型对测试集计算得出推广误差

**方差与偏差**

对于训练集，当d较小时，模型拟合程度更低，误差较大，随着d的增长，拟合程度提高，误差减小。
而对于交叉验证集,当 d 较小时,模型拟合程度低,误差较大;但是随着 d 的增长,误差呈现先减小后增大的趋势,转折点是我们的模型开始过拟合训练数据集的时候。

![](http://pic-10062852.cos.myqcloud.com/%E8%AF%8A%E6%96%AD%E6%96%B9%E5%B7%AE%E6%B4%BB%E5%81%8F%E5%B7%AE.png)
>训练集误差和交叉验证集误差近似时:偏差/欠拟合
交叉验证集误差远大于训练集误差时:方差/过拟合

**归一化方差与偏差**

在我们在训练模型的过程中,一般会使用一些归一化方法来防止过拟合。但是可能会归一化的程度太高或太小了,即我们在选择 λ 的值时也需要思考与刚才选择多项式模型次数类似的问题。
我们选择一系列的想要测试的 λ 值,通常是 0-10 之间的呈现 2 倍关系的值(如:
0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10 共 12 个)。 我们同样把数据分为训练集、交叉验证集和测试集。
![](http://pic-10062852.cos.myqcloud.com/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E5%B7%AE%E4%B8%8E%E5%81%8F%E5%B7%AE.png)
选择 λ 的方法为:
 1. 使用训练集训练出 12 个不同程度归一化的模型
 2. 用 12 模型分别对交叉验证集计算的出交叉验证误差
 3. 选择得出交叉验证误差最小的模型
 4. 运用步骤 3 中选出模型对测试集计算得出推广误差,也可以同时将训练集和交叉验证集模型的代价函数误差与 λ 的值绘制在一张图表上:
 ![](http://pic-10062852.cos.myqcloud.com/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E5%B7%AE%E4%B8%8E%E5%81%8F%E5%B7%AE%E5%9B%BE.png)
 
 - 当 λ 较小时,训练集误差较小(过拟合)而交叉验证集误差较大
 -  随着 λ 的增加,训练集误差不断增加(欠拟合),而交叉验证集误差则是先减小后增加