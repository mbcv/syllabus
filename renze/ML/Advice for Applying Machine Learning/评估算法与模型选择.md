####Debugging a learning algorithm###
当使用假设函数测试一组新的样本时产生了巨大的误差，这时应该怎么做？

 - 获取更多的训练样本（有时，更多的样本也于事无补）
 - 尝试更少的特征集
 - 或许需要用更多的特征
 - 尝试增加多项式特征
 - 增大或减小lambda
 
 >机器学习诊断法：是一种测试法，通过执行这种测试，能够深入了解某种算法是否有用，通常也能够告诉你，如果想要改进一种算法的效果，需要什么样的尝试。
 
评估一个假设函数：
将训练集分为两部分，前70%用作新的训练集，后30%用作测试集。（如果训练集是有序的或者是有规律的，则随机选取70%做训练集）

最小化训练误差 J(θ)

>**线性回归**：
![线性回归](http://pic-10062852.cos.myqcloud.com/mintheta.jpg)

>**逻辑回归**：
除了利用测试数据集来计算代价函数外
![逻辑回归](http://pic-10062852.cos.myqcloud.com/logisticMintheta.png)
还可以计算误分类的比率，对于每一个测试集实例，计算：
![误分类比率](http://pic-10062852.cos.myqcloud.com/%E8%AF%AF%E5%88%86%E7%B1%BB%E6%AF%94%E7%8E%87.png)
然后对计算结果求平均。


**交叉验证**
假设要在10个不同次数的二项式模型之间进行选择:
![10model](http://pic-10062852.cos.myqcloud.com/10model.png)

把训练集分为3部分，第一部分为训练集，第二部分为交叉验证集，第三部分为测试集。(60%  20%  20%)
![error](http://pic-10062852.cos.myqcloud.com/train-vali-testerror.png)

模型选择的方法：

 - 使用训练集训练出10个模型
 - 用10个模型分别对交叉验证集计算得到交叉验证误差（即代价函数的值）
 - 选取代价函数最小的模型
 - 用选出的模型对测试集计算得出推广误差

**方差与偏差**

对于训练集，当d较小时，模型拟合程度更低，误差较大，随着d的增长，拟合程度提高，误差减小。
而对于交叉验证集,当 d 较小时,模型拟合程度低,误差较大;但是随着 d 的增长,误差呈现先减小后增大的趋势,转折点是我们的模型开始过拟合训练数据集的时候。

![](http://pic-10062852.cos.myqcloud.com/%E8%AF%8A%E6%96%AD%E6%96%B9%E5%B7%AE%E6%B4%BB%E5%81%8F%E5%B7%AE.png)
>训练集误差和交叉验证集误差近似时:偏差/欠拟合
交叉验证集误差远大于训练集误差时:方差/过拟合

**归一化方差与偏差**

在我们在训练模型的过程中,一般会使用一些归一化方法来防止过拟合。但是可能会归一化的程度太高或太小了,即我们在选择 λ 的值时也需要思考与刚才选择多项式模型次数类似的问题。
我们选择一系列的想要测试的 λ 值,通常是 0-10 之间的呈现 2 倍关系的值(如:
0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10 共 12 个)。 我们同样把数据分为训练集、交叉验证集和测试集。
![](http://pic-10062852.cos.myqcloud.com/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E5%B7%AE%E4%B8%8E%E5%81%8F%E5%B7%AE.png)
选择 λ 的方法为:
 1. 使用训练集训练出 12 个不同程度归一化的模型
 2. 用 12 模型分别对交叉验证集计算的出交叉验证误差
 3. 选择得出交叉验证误差最小的模型
 4. 运用步骤 3 中选出模型对测试集计算得出推广误差,也可以同时将训练集和交叉验证集模型的代价函数误差与 λ 的值绘制在一张图表上:
 ![](http://pic-10062852.cos.myqcloud.com/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E5%B7%AE%E4%B8%8E%E5%81%8F%E5%B7%AE%E5%9B%BE.png)
 
 - 当 λ 较小时,训练集误差较小(过拟合)而交叉验证集误差较大
 -  随着 λ 的增加,训练集误差不断增加(欠拟合),而交叉验证集误差则是先减小后增加

**学习曲线**
使用学习曲线来判断一个学习算法是否处于偏差 方差问题。（学习曲线是将训练集误差和交叉验证误差作为训练集实例数量(m)的函数绘制的图表）

高偏差/欠拟合 学习曲线
![](http://pic-10062852.cos.myqcloud.com/%E9%AB%98%E5%81%8F%E5%B7%AE%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF.png)
无论训练集有多大误差都不会有太大改观。

高方差/过拟合 学习曲线
![](http://pic-10062852.cos.myqcloud.com/%E9%AB%98%E6%96%B9%E5%B7%AE%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF.png)
假设我们使用一个非常高次的多项式模型,并且归一化非常小,可以看出,当交叉验证集误差远大于训练集误差时,往训练集增加更多数据可以提高模型的效果。

 - 获取更多的训练样本→解决高方差
 - 尝试更少的特征集→解决高方差
 - 或许需要用更多的特征→解决高偏差
 - 尝试增加多项式特征→解决高偏差
 - 减小lambda→解决高偏差
 - 增大lambad→解决高方差
 
神经网络
![](http://pic-10062852.cos.myqcloud.com/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88.png)

使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小。使用较大的神经网络，类似于参数较多的情况，容日导致高方差和过拟合，计算代价比较大，可以通过归一化来调整使更加适应数据。
**通常选择较大的神经网络并采用归一化处理会比采用较小的神经网络效果更好。**
对于隐藏层层数的选择，通常从一层开始逐渐增加层数，针对不同隐藏层层数的神经网络训练神经网络, 然后选择交叉验证集代价最小的神经网络。